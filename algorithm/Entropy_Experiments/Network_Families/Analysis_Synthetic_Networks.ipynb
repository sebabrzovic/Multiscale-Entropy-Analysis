{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducing Figure 1: Multiscale Entropy Analysis on Synthetic Networks\n",
    "\n",
    "This notebook reproduces Figure 1 from our paper, which demonstrates how normalized entropy evolves across different reduction levels for four families of synthetic graphs: Ring, Barabási-Albert, Random Regular, and Grid networks.\n",
    "### Overview\n",
    "\n",
    "We implement the multiscale entropy framework described in Section 4.1 of the paper. The experiment involves:\n",
    "\n",
    "1. Graph Generation: Creating 10 instances each of Ring, Barabási-Albert, Random Regular, and Grid graphs at three different sizes (500, 1500, and 2500 nodes)\n",
    "2. Spectral Reduction: Applying graph coarsening at multiple scales (100%, 80%, 60%, 40%, 20% of original size)\n",
    "3. Entropy Calculation: Computing compression-based entropy using arithmetic encoding at each reduction level\n",
    "4. Normalization: Normalizing against Erdős-Rényi random graphs with matched size and density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==1.5.3 in /home/sebabrzovic/.local/lib/python3.8/site-packages (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.20.3; python_version < \"3.10\" in /home/sebabrzovic/.local/lib/python3.8/site-packages (from pandas==1.5.3) (1.24.4)\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas==1.5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1441/912229180.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "##get current file directory\n",
    "current_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "##get the parent directory\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "# Add the src directory to sys.path\n",
    "src_dir = os.path.join(parent_dir, '../')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "from algorithm.calculo_entropia import *\n",
    "import algorithm.calculo_entropia\n",
    "\n",
    "from algorithm.coarsening_utils import *\n",
    "import algorithm.graph_utils\n",
    "import algorithm.coarsening_utils as cu\n",
    "from algorithm.coarsening_utils import plot_coarsening_vertical\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import networkx as nx\n",
    "import pygsp as gsp\n",
    "from pygsp import graphs\n",
    "gsp.plotting.BACKEND = 'matplotlib'\n",
    "\n",
    "import pickle\n",
    "\n",
    "def save_graphs(graph_dict, filename):\n",
    "    \"\"\"\n",
    "    Save the dictionary of graphs to a file.\n",
    "    \"\"\"\n",
    "    # Convert PyGSP graphs to NetworkX graphs for easier serialization\n",
    "    nx_graph_dict = {\n",
    "        size: [nx.from_scipy_sparse_array(g.W) for g in graphs]\n",
    "        for size, graphs in graph_dict.items()\n",
    "    }\n",
    "    \n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(nx_graph_dict, f)\n",
    "    print(f\"Graphs saved to {filename}\")\n",
    "\n",
    "def load_graphs(filename):\n",
    "    \"\"\"\n",
    "    Load the dictionary of graphs from a file.\n",
    "    \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        nx_graph_dict = pickle.load(f)\n",
    "    print(f\"Graphs loaded from {filename}\")\n",
    "    return nx_graph_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle  \n",
    "# load the data \n",
    "infile = open('./CommunityFitNet_updated.pickle','rb')  \n",
    "df = pickle.load(infile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read edge lists for all networks\n",
    "df_edgelists = df['edges_id'] # column 'edges_id' in dataframe df includes the edge list \n",
    "                              # for each network \n",
    " \n",
    "# extract the edge list for the first network \n",
    "edges_orig = df_edgelists.iloc[0] # a numpy array of edge list for original graph \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Graph Generation\n",
    "We generate synthetic networks across four families and three size scales. Each family exhibits distinct structural properties:\n",
    "\n",
    "- Ring graphs: Regular lattice with random shortcuts (small-world-like)\n",
    "- Barabási-Albert: Scale-free networks with power-law degree distribution\n",
    "- Random Regular: Uniform degree distribution with random connectivity\n",
    "- Grid graphs: 2D lattice structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pygsp import graphs\n",
    "import networkx as nx\n",
    "import pickle\n",
    "\n",
    "# Setting plot functions for family\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import numpy as np\n",
    "from cycler import cycler\n",
    "\n",
    "def get_nodes_in_range(graph_data, min_nodes, max_nodes):\n",
    "    try:\n",
    "        nodes = graph_data['reductions']['100']['number_nodes']\n",
    "        return min_nodes <= nodes < max_nodes\n",
    "    except (KeyError, TypeError):\n",
    "        return False\n",
    "\n",
    "def safe_get_entropy_value(graph_data, level):\n",
    "    \"\"\"Safely get entropy value, return None if not available.\"\"\"\n",
    "    try:\n",
    "        return graph_data['reductions'][str(level)]['entropy_arithmetic']['normalized']\n",
    "    except (KeyError, TypeError):\n",
    "        return None\n",
    "\n",
    "def get_valid_entropy_values(graph_data, reduction_levels):\n",
    "    \"\"\"Get entropy values and their corresponding levels.\"\"\"\n",
    "    values = []\n",
    "    valid_levels = []\n",
    "    for level in reduction_levels:\n",
    "        value = safe_get_entropy_value(graph_data, level)\n",
    "        if value is not None:\n",
    "            values.append(value)\n",
    "            valid_levels.append(level)\n",
    "    return valid_levels, values\n",
    "\n",
    "def get_y_axis_limits(entropy_values_list, padding=0.1):\n",
    "    \"\"\"Calculate appropriate y-axis limits based on data\"\"\"\n",
    "    all_values = []\n",
    "    \n",
    "    # Handle both list of lists and list of floats\n",
    "    for values in entropy_values_list:\n",
    "        if isinstance(values, (list, tuple)):\n",
    "            all_values.extend([v for v in values if v is not None])\n",
    "        elif isinstance(values, (int, float)):\n",
    "            all_values.append(values)\n",
    "    \n",
    "    if not all_values:\n",
    "        return 0.5, 1.1\n",
    "    \n",
    "    min_val = min(all_values)\n",
    "    max_val = max(all_values)\n",
    "    \n",
    "    # Add padding\n",
    "    range_val = max_val - min_val\n",
    "    min_val = max(0, min_val - range_val * padding)\n",
    "    max_val = max_val + range_val * padding\n",
    "    \n",
    "    return min_val, max_val\n",
    "\n",
    "def plot_family_specific(json_data, family_name, node_ranges, figsize=(25, 20)):\n",
    "    n_ranges = len(node_ranges)\n",
    "    n_cols = 2\n",
    "    n_rows = (n_ranges + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "    if n_rows == 1 and n_cols == 1:\n",
    "        axes = np.array([axes])\n",
    "    elif n_rows == 1:\n",
    "        axes = np.array([axes])\n",
    "    elif n_cols == 1:\n",
    "        axes = np.array([[ax] for ax in axes])\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    reduction_levels = [100, 80, 60, 40, 20]\n",
    "    family_data = json_data[family_name]\n",
    "    \n",
    "    # First pass to get global y-axis limits\n",
    "    all_entropy_values = []\n",
    "    for min_nodes, max_nodes in node_ranges:\n",
    "        filtered_graphs = {name: data for name, data in family_data.items() \n",
    "                         if get_nodes_in_range(data, min_nodes, max_nodes)}\n",
    "        \n",
    "        for graph_data in filtered_graphs.values():\n",
    "            _, values = get_valid_entropy_values(graph_data, reduction_levels)\n",
    "            all_entropy_values.extend(values)  # values is already a list\n",
    "    \n",
    "    y_min, y_max = get_y_axis_limits(all_entropy_values)\n",
    "    \n",
    "    # Plot each range in its own subplot\n",
    "    for range_idx, (min_nodes, max_nodes) in enumerate(node_ranges):\n",
    "        ax = axes[range_idx]\n",
    "        range_label = f\"{min_nodes}-{max_nodes if max_nodes != float('inf') else '+'}\"\n",
    "        \n",
    "        filtered_graphs = {name: data for name, data in family_data.items() \n",
    "                         if get_nodes_in_range(data, min_nodes, max_nodes)}\n",
    "        \n",
    "        if filtered_graphs:\n",
    "            n_graphs = len(filtered_graphs)\n",
    "            colors = plt.cm.rainbow(np.linspace(0, 1, n_graphs))\n",
    "            \n",
    "            for graph_idx, (graph_name, graph_data) in enumerate(filtered_graphs.items()):\n",
    "                valid_levels, entropy_values = get_valid_entropy_values(graph_data, reduction_levels)\n",
    "                \n",
    "                if valid_levels:\n",
    "                    node_count = graph_data['reductions']['100']['number_nodes']\n",
    "                    short_name = f\"{graph_name[:20]}... ({node_count})\"\n",
    "                    \n",
    "                    ax.plot(valid_levels, entropy_values,\n",
    "                           marker='o',\n",
    "                           linestyle='-',\n",
    "                           linewidth=1.5,\n",
    "                           markersize=6,\n",
    "                           label=short_name,\n",
    "                           color=colors[graph_idx],\n",
    "                           alpha=0.7)\n",
    "        \n",
    "        ax.set_xlabel('Graph Portion (%)', fontsize=10)\n",
    "        ax.set_ylabel('Normalized Entropy', fontsize=10)\n",
    "        ax.set_title(f'Range: {range_label} nodes (n={len(filtered_graphs)})', \n",
    "                    fontsize=12)\n",
    "        \n",
    "        ax.grid(True, linestyle='--', alpha=0.3)\n",
    "        ax.set_xticks(reduction_levels)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=8)\n",
    "        ax.invert_xaxis()\n",
    "        ax.set_ylim(y_min, y_max)\n",
    "        \n",
    "        if len(filtered_graphs) > 0:\n",
    "            ax.legend(bbox_to_anchor=(1.02, 1),\n",
    "                     loc='upper left',\n",
    "                     borderaxespad=0.,\n",
    "                     fontsize=8,\n",
    "                     ncol=1)\n",
    "    \n",
    "    # Remove empty subplots\n",
    "    for idx in range(len(node_ranges), len(axes)):\n",
    "        fig.delaxes(axes[idx])\n",
    "    \n",
    "    plt.suptitle(f'Entropy Reduction Patterns for {family_name} Networks',\n",
    "                 fontsize=16,\n",
    "                 fontweight='bold',\n",
    "                 y=0.95)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 0.95, 0.95])\n",
    "    return fig\n",
    "\n",
    "# Set parameters\n",
    "node_sizes = [2500, 1500, 500]\n",
    "num_graphs = 10\n",
    "\n",
    "# Dictionary to store all graphs\n",
    "# Structure: graphs_dict[graph_type][node_size] = list_of_graphs\n",
    "graphs_dict = {\n",
    "    'ring': {size: [] for size in node_sizes},\n",
    "    'barabasi': {size: [] for size in node_sizes},\n",
    "    'regular': {size: [] for size in node_sizes},\n",
    "    'grid': {size: [] for size in node_sizes}\n",
    "}\n",
    "\n",
    "# Create graphs for each type and size\n",
    "for N in node_sizes:\n",
    "    print(f\"\\nCreating graphs with {N} nodes...\")\n",
    "    \n",
    "    for i in range(num_graphs):\n",
    "        print(f\"Creating set {i+1}/{num_graphs}...\")\n",
    "        \n",
    "        # 1. Ring Graph with random edges\n",
    "        G_ring = graphs.Ring(N=N, k=1)\n",
    "        p = 0.005\n",
    "        for u in range(N):\n",
    "            for v in range(u+2, N):\n",
    "                if np.random.random() < p:\n",
    "                    G_ring.W[u, v] = G_ring.W[v, u] = 1\n",
    "        graphs_dict['ring'][N].append(G_ring)\n",
    "        \n",
    "        # 2. Barabasi-Albert Graph\n",
    "        G_ba = graphs.BarabasiAlbert(N=N)\n",
    "        graphs_dict['barabasi'][N].append(G_ba)\n",
    "        \n",
    "        # 3. Random Regular Graph\n",
    "        G_nx_regular = nx.random_regular_graph(d=5, n=N)\n",
    "        W_regular = nx.adjacency_matrix(G_nx_regular)\n",
    "        G_regular = graphs.Graph(W_regular)\n",
    "        graphs_dict['regular'][N].append(G_regular)\n",
    "        \n",
    "        # 4. Grid Graph\n",
    "        # Calculate grid dimensions\n",
    "        m, n = int(np.sqrt(N)), int(np.sqrt(N))\n",
    "        while m * n != N:\n",
    "            m -= 1\n",
    "            n = N // m\n",
    "        G_nx_grid = nx.grid_2d_graph(m=m, n=n)\n",
    "        W_grid = nx.adjacency_matrix(G_nx_grid)\n",
    "        G_grid = graphs.Graph(W_grid)\n",
    "        graphs_dict['grid'][N].append(G_grid)\n",
    "\n",
    "# Save all graphs in one file\n",
    "print(\"\\nSaving all graphs...\")\n",
    "with open('all_graphs.pkl', 'wb') as f:\n",
    "    pickle.dump(graphs_dict, f)\n",
    "print(\"Saved all graphs to all_graphs.pkl\")\n",
    "\n",
    "# Print information about the saved graphs\n",
    "print(\"\\nGraph Information:\")\n",
    "for graph_type in graphs_dict:\n",
    "    print(f\"\\n{graph_type.upper()} Graphs:\")\n",
    "    for size in node_sizes:\n",
    "        num_graphs = len(graphs_dict[graph_type][size])\n",
    "        sample_graph = graphs_dict[graph_type][size][0]\n",
    "        print(f\"\\nSize {size}:\")\n",
    "        print(f\"Number of graphs: {num_graphs}\")\n",
    "        print(f\"Nodes per graph: {sample_graph.N}\")\n",
    "        print(f\"Edges per graph: {sample_graph.W.nnz//2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ring': {2500: [<pygsp.graphs.ring.Ring object at 0x7f2f25309520>, <pygsp.graphs.ring.Ring object at 0x7f2ee40ee070>, <pygsp.graphs.ring.Ring object at 0x7f2ee2f08e20>, <pygsp.graphs.ring.Ring object at 0x7f2ee41d8d30>, <pygsp.graphs.ring.Ring object at 0x7f2ee30bbdf0>, <pygsp.graphs.ring.Ring object at 0x7f2ee1e6fd30>, <pygsp.graphs.ring.Ring object at 0x7f2ee38a9dc0>, <pygsp.graphs.ring.Ring object at 0x7f2ee0e11d30>, <pygsp.graphs.ring.Ring object at 0x7f2ee2fd0d60>, <pygsp.graphs.ring.Ring object at 0x7f2ee2067fa0>], 1500: [<pygsp.graphs.ring.Ring object at 0x7f2ee388b490>, <pygsp.graphs.ring.Ring object at 0x7f2edf8c5f40>, <pygsp.graphs.ring.Ring object at 0x7f2ee1043fa0>, <pygsp.graphs.ring.Ring object at 0x7f2ee0514e80>, <pygsp.graphs.ring.Ring object at 0x7f2edf4eaf70>, <pygsp.graphs.ring.Ring object at 0x7f2ee012c580>, <pygsp.graphs.ring.Ring object at 0x7f2edecbdd30>, <pygsp.graphs.ring.Ring object at 0x7f2edf79a0a0>, <pygsp.graphs.ring.Ring object at 0x7f2edea79cd0>, <pygsp.graphs.ring.Ring object at 0x7f2ede48af70>], 500: [<pygsp.graphs.ring.Ring object at 0x7f2ee0ab16a0>, <pygsp.graphs.ring.Ring object at 0x7f2edf4abd00>, <pygsp.graphs.ring.Ring object at 0x7f2edebf7f70>, <pygsp.graphs.ring.Ring object at 0x7f2ee0294dc0>, <pygsp.graphs.ring.Ring object at 0x7f2edf9bb100>, <pygsp.graphs.ring.Ring object at 0x7f2eded98f40>, <pygsp.graphs.ring.Ring object at 0x7f2ede91ad00>, <pygsp.graphs.ring.Ring object at 0x7f2edde97f70>, <pygsp.graphs.ring.Ring object at 0x7f2eddbeb040>, <pygsp.graphs.ring.Ring object at 0x7f2eddb13f10>]}, 'barabasi': {2500: [<pygsp.graphs.barabasialbert.BarabasiAlbert object at 0x7f2ee446a670>, <pygsp.graphs.barabasialbert.BarabasiAlbert object at 0x7f2f253095b0>, <pygsp.graphs.barabasialbert.BarabasiAlbert object at 0x7f2f25309580>, <pygsp.graphs.barabasialbert.BarabasiAlbert object at 0x7f2ee2ce6d00>, <pygsp.graphs.barabasialbert.BarabasiAlbert object at 0x7f2ee2e447c0>, <pygsp.graphs.barabasialbert.BarabasiAlbert object at 0x7f2ee2ca1f40>, <pygsp.graphs.barabasialbert.BarabasiAlbert object at 0x7f2ee2619e80>, <pygsp.graphs.barabasialbert.BarabasiAlbert object at 0x7f2ee3e46a60>, <pygsp.graphs.barabasialbert.BarabasiAlbert object at 0x7f2ee2305130>, <pygsp.graphs.barabasialbert.BarabasiAlbert object at 0x7f2ee30bba00>], 1500: [<pygsp.graphs.barabasialbert.BarabasiAlbert object at 0x7f2ee0e11d90>, <pygsp.graphs.barabasialbert.BarabasiAlbert object at 0x7f2ee097a1f0>, <pygsp.graphs.barabasialbert.BarabasiAlbert object at 0x7f2ee24587c0>, <pygsp.graphs.barabasialbert.BarabasiAlbert object at 0x7f2ee0514fa0>, <pygsp.graphs.barabasialbert.BarabasiAlbert object at 0x7f2ee012ce20>, <pygsp.graphs.barabasialbert.BarabasiAlbert object at 0x7f2edf53ac70>, <pygsp.graphs.barabasialbert.BarabasiAlbert object at 0x7f2eded45310>, <pygsp.graphs.barabasialbert.BarabasiAlbert object at 0x7f2edf5d21c0>, <pygsp.graphs.barabasialbert.BarabasiAlbert object at 0x7f2ede79f160>, <pygsp.graphs.barabasialbert.BarabasiAlbert object at 0x7f2ede7ccfa0>], 500: [<pygsp.graphs.barabasialbert.BarabasiAlbert object at 0x7f2edea8af70>, <pygsp.graphs.barabasialbert.BarabasiAlbert object at 0x7f2edf083a30>, <pygsp.graphs.barabasialbert.BarabasiAlbert object at 0x7f2edf4abf70>, <pygsp.graphs.barabasialbert.BarabasiAlbert object at 0x7f2ee0294ee0>, <pygsp.graphs.barabasialbert.BarabasiAlbert object at 0x7f2edeffa4c0>, <pygsp.graphs.barabasialbert.BarabasiAlbert object at 0x7f2ee1da89a0>, <pygsp.graphs.barabasialbert.BarabasiAlbert object at 0x7f2ede91abe0>, <pygsp.graphs.barabasialbert.BarabasiAlbert object at 0x7f2edde97f40>, <pygsp.graphs.barabasialbert.BarabasiAlbert object at 0x7f2eddbeb0a0>, <pygsp.graphs.barabasialbert.BarabasiAlbert object at 0x7f2eddbb27f0>]}, 'regular': {2500: [<pygsp.graphs.graph.Graph object at 0x7f2f25309550>, <pygsp.graphs.graph.Graph object at 0x7f2ee3a90d30>, <pygsp.graphs.graph.Graph object at 0x7f2ee2f45f70>, <pygsp.graphs.graph.Graph object at 0x7f2ee26d6820>, <pygsp.graphs.graph.Graph object at 0x7f2ee30fa6d0>, <pygsp.graphs.graph.Graph object at 0x7f2ee1eae910>, <pygsp.graphs.graph.Graph object at 0x7f2ee3966e50>, <pygsp.graphs.graph.Graph object at 0x7f2ee0e4e310>, <pygsp.graphs.graph.Graph object at 0x7f2ee300d340>, <pygsp.graphs.graph.Graph object at 0x7f2ee033cac0>], 1500: [<pygsp.graphs.graph.Graph object at 0x7f2ee007bb80>, <pygsp.graphs.graph.Graph object at 0x7f2edf915b80>, <pygsp.graphs.graph.Graph object at 0x7f2ee0dadcd0>, <pygsp.graphs.graph.Graph object at 0x7f2ee04e5b50>, <pygsp.graphs.graph.Graph object at 0x7f2edf53ac10>, <pygsp.graphs.graph.Graph object at 0x7f2edef4ea90>, <pygsp.graphs.graph.Graph object at 0x7f2edfb10670>, <pygsp.graphs.graph.Graph object at 0x7f2ee03f8d30>, <pygsp.graphs.graph.Graph object at 0x7f2edeac8f70>, <pygsp.graphs.graph.Graph object at 0x7f2ede459c10>], 500: [<pygsp.graphs.graph.Graph object at 0x7f2ede0a5a00>, <pygsp.graphs.graph.Graph object at 0x7f2ee221df40>, <pygsp.graphs.graph.Graph object at 0x7f2edebe6d60>, <pygsp.graphs.graph.Graph object at 0x7f2ee026da60>, <pygsp.graphs.graph.Graph object at 0x7f2edfdc3e20>, <pygsp.graphs.graph.Graph object at 0x7f2edee05d60>, <pygsp.graphs.graph.Graph object at 0x7f2ede986340>, <pygsp.graphs.graph.Graph object at 0x7f2edde84be0>, <pygsp.graphs.graph.Graph object at 0x7f2eddcc3dc0>, <pygsp.graphs.graph.Graph object at 0x7f2eddb00d60>]}, 'grid': {2500: [<pygsp.graphs.graph.Graph object at 0x7f2f25331d60>, <pygsp.graphs.graph.Graph object at 0x7f2ee36c13a0>, <pygsp.graphs.graph.Graph object at 0x7f2ee2e44760>, <pygsp.graphs.graph.Graph object at 0x7f2ee23050d0>, <pygsp.graphs.graph.Graph object at 0x7f2ee2067f40>, <pygsp.graphs.graph.Graph object at 0x7f2ee1adb1c0>, <pygsp.graphs.graph.Graph object at 0x7f2ee21546d0>, <pygsp.graphs.graph.Graph object at 0x7f2ee0a7bb80>, <pygsp.graphs.graph.Graph object at 0x7f2ee1cbbbb0>, <pygsp.graphs.graph.Graph object at 0x7f2ee0cad100>], 1500: [<pygsp.graphs.graph.Graph object at 0x7f2edfcaa430>, <pygsp.graphs.graph.Graph object at 0x7f2edf6b7a30>, <pygsp.graphs.graph.Graph object at 0x7f2edff0fb80>, <pygsp.graphs.graph.Graph object at 0x7f2ee0207a00>, <pygsp.graphs.graph.Graph object at 0x7f2edf2ddac0>, <pygsp.graphs.graph.Graph object at 0x7f2edecef940>, <pygsp.graphs.graph.Graph object at 0x7f2edfe11520>, <pygsp.graphs.graph.Graph object at 0x7f2edf79abe0>, <pygsp.graphs.graph.Graph object at 0x7f2ede86be20>, <pygsp.graphs.graph.Graph object at 0x7f2ede27cac0>], 500: [<pygsp.graphs.graph.Graph object at 0x7f2ee03b5910>, <pygsp.graphs.graph.Graph object at 0x7f2edf07af40>, <pygsp.graphs.graph.Graph object at 0x7f2ede99e520>, <pygsp.graphs.graph.Graph object at 0x7f2edf043220>, <pygsp.graphs.graph.Graph object at 0x7f2edf92b5e0>, <pygsp.graphs.graph.Graph object at 0x7f2edebaf520>, <pygsp.graphs.graph.Graph object at 0x7f2eddf27610>, <pygsp.graphs.graph.Graph object at 0x7f2edddae3a0>, <pygsp.graphs.graph.Graph object at 0x7f2eddbeb580>, <pygsp.graphs.graph.Graph object at 0x7f2edda2a520>]}}\n"
     ]
    }
   ],
   "source": [
    "print(graphs_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Multiscale Reduction and Entropy Calculation\n",
    "In this step, we apply the spectral coarsening algorithm (Section 3.1) to each graph at multiple reduction levels, then compute the normalized compression entropy at each scale. This process generates the data file synthetic_graphs_analysis.json containing entropy measurements across all graphs and reduction levels.\n",
    "Note: The code for this step is implemented in the project files coarsening_utils.py and calculo_entropia.py. Run the reduction pipeline to generate the analysis file before proceeding to visualization.\n",
    "\n",
    "## Step 3: Visualization - Creating Figure 1\n",
    "Now we load the processed data and generate the visualization that appears as Figure 1 in the paper. We create two types of plots:\n",
    "\n",
    "1. By network size: Comparing all four families at each size scale\n",
    "2. By network family: Showing how each family behaves across different sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from pygsp import graphs\n",
    "import json\n",
    "\n",
    "def get_graph_edges(graph):\n",
    "    \"\"\"Safely get number of edges from a PyGSP graph\"\"\"\n",
    "    try:\n",
    "        # Try to use the stored number of edges\n",
    "        return graph.Ne\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            # Calculate from the weight matrix\n",
    "            return int(graph.W.nnz / 2)  # Divide by 2 for undirected graphs\n",
    "        except:\n",
    "            # Count non-zero elements in adjacency matrix\n",
    "            return int(np.sum(graph.W.toarray() > 0) / 2)\n",
    "\n",
    "def process_synthetic_graphs(synthetic_graphs):\n",
    "    \"\"\"Convert synthetic graphs data into our analysis format\"\"\"\n",
    "    json_data = {}\n",
    "    \n",
    "    for family_name, size_dict in synthetic_graphs.items():\n",
    "        print(f\"\\nProcessing {family_name} graphs...\")\n",
    "        family_data = {}\n",
    "        \n",
    "        for size, graph_list in size_dict.items():\n",
    "            print(f\"Processing size {size}, {len(graph_list)} graphs\")\n",
    "            \n",
    "            # Process each graph in the list\n",
    "            for idx, graph in enumerate(graph_list):\n",
    "                graph_name = f\"{family_name}_{size}_{idx}\"\n",
    "                print(f\"Processing {graph_name}\")\n",
    "                \n",
    "                # Initialize reduction data\n",
    "                reductions = {}\n",
    "                current_graph = graph\n",
    "                \n",
    "                try:\n",
    "                    # Calculate initial metrics\n",
    "                    N = current_graph.N  # Original number of nodes\n",
    "                    E = get_graph_edges(current_graph)  # Original number of edges\n",
    "                    \n",
    "                    # Store original graph metrics (100%)\n",
    "                    reductions['100'] = {\n",
    "                        'number_nodes': N,\n",
    "                        'number_edges': E,\n",
    "                        'ave_degree': 2 * E / N if N > 0 else 0,\n",
    "                    }\n",
    "                    \n",
    "                    # Perform reductions\n",
    "                    for reduction in [80, 60, 40, 20]:\n",
    "                        try:\n",
    "                            # Calculate reduction ratio\n",
    "                            r = 1 - (reduction/100)\n",
    "                            \n",
    "                            # Perform coarsening\n",
    "                            C, Gc, Call, Gall = coarsen(current_graph, K=10, r=r)\n",
    "                            \n",
    "                            if Gc is not None:\n",
    "                                n = Gc.N  # Number of nodes after reduction\n",
    "                                e = get_graph_edges(Gc)  # Number of edges after reduction\n",
    "                                \n",
    "                                reductions[str(reduction)] = {\n",
    "                                    'number_nodes': n,\n",
    "                                    'number_edges': e,\n",
    "                                    'ave_degree': 2 * e / n if n > 0 else 0,\n",
    "                                }\n",
    "                                \n",
    "                                # Calculate entropy metrics\n",
    "                                G_nx = nx.from_scipy_sparse_array(Gc.W)\n",
    "                                entropy_metrics = get_entropy_metadata_aritmethicEncoding(G_nx)\n",
    "                                \n",
    "                                reductions[str(reduction)]['entropy_arithmetic'] = {\n",
    "                                    'graph': entropy_metrics['Grafo'],\n",
    "                                    'random': entropy_metrics['Grafo_r'],\n",
    "                                    'normalized': entropy_metrics['Entropy Normalizado']\n",
    "                                }\n",
    "                                \n",
    "                        except Exception as e:\n",
    "                            print(f\"Error in reduction {reduction}% for {graph_name}: {str(e)}\")\n",
    "                            continue\n",
    "                    \n",
    "                    # Calculate entropy metrics for original graph\n",
    "                    try:\n",
    "                        G_nx = nx.from_scipy_sparse_array(graph.W)\n",
    "                        entropy_metrics = get_entropy_metadata_aritmethicEncoding(G_nx)\n",
    "                        reductions['100']['entropy_arithmetic'] = {\n",
    "                            'graph': entropy_metrics['Grafo'],\n",
    "                            'random': entropy_metrics['Grafo_r'],\n",
    "                            'normalized': entropy_metrics['Entropy Normalizado']\n",
    "                        }\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error calculating original entropy for {graph_name}: {str(e)}\")\n",
    "                    \n",
    "                    # Add to family data\n",
    "                    family_data[graph_name] = {\n",
    "                        'Name': graph_name,\n",
    "                        'Subdomain': 'Synthetic',\n",
    "                        'Node_Type': 'Vertex',\n",
    "                        'Edge_Type': family_name,\n",
    "                        'reductions': reductions\n",
    "                    }\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing graph {graph_name}: {str(e)}\")\n",
    "                    continue\n",
    "        \n",
    "        json_data[family_name] = family_data\n",
    "    \n",
    "    return json_data\n",
    "\n",
    "# Define ranges for synthetic graphs\n",
    "synthetic_ranges = {\n",
    "    'ring': [(0, 1000), (1000, 2000), (2000, float('inf'))],\n",
    "    'barabasi': [(0, 1000), (1000, 2000), (2000, float('inf'))],\n",
    "    'regular': [(0, 1000), (1000, 2000), (2000, float('inf'))],\n",
    "    'grid': [(0, 1000), (1000, 2000), (2000, float('inf'))]\n",
    "}\n",
    "\n",
    "# Load and process the data\n",
    "try:\n",
    "    print(\"Loading synthetic graphs...\")\n",
    "    with open('all_graphs.pkl', 'rb') as f:\n",
    "        synthetic_graphs = pickle.load(f)\n",
    "    \n",
    "    print(\"Processing graphs...\")\n",
    "    json_data = process_synthetic_graphs(synthetic_graphs)\n",
    "    \n",
    "    print(\"Saving processed data...\")\n",
    "    with open('synthetic_graphs_analysis.json', 'w') as f:\n",
    "        json.dump(json_data, f, indent=2)\n",
    "    \n",
    "    print(\"Creating plots...\")\n",
    "    for family_name, ranges in synthetic_ranges.items():\n",
    "        try:\n",
    "            fig = plot_family_specific(json_data, family_name, ranges)\n",
    "            if fig is not None:\n",
    "                plt.savefig(f'entropy_{family_name}_synthetic_by_ranges.png',\n",
    "                           bbox_inches='tight',\n",
    "                           dpi=300)\n",
    "                plt.close()\n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting {family_name}: {str(e)}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Error in main execution: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_size_specific(json_data, node_size, figsize=(15, 10)):\n",
    "    \"\"\"Plot all families for a specific node size.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    reduction_levels = [100, 80, 60, 40, 20]\n",
    "    \n",
    "    # Different color for each family\n",
    "    colors = {'ring': 'blue', 'barabasi': 'red', 'regular': 'green', 'grid': 'purple'}\n",
    "    markers = {'ring': 'o', 'barabasi': 's', 'regular': '^', 'grid': 'D'}\n",
    "    \n",
    "    for family_name in ['ring', 'barabasi', 'regular', 'grid']:\n",
    "        entropy_values = []\n",
    "        \n",
    "        # Get all graphs of this size for this family\n",
    "        for graph_name, graph_data in json_data[family_name].items():\n",
    "            if f\"{node_size}\" in graph_name:\n",
    "                values = [graph_data['reductions'][str(level)]['entropy_arithmetic']['normalized'] \n",
    "                         for level in reduction_levels]\n",
    "                entropy_values.append(values)\n",
    "        \n",
    "        # Plot average with error bars\n",
    "        if entropy_values:\n",
    "            mean_values = np.mean(entropy_values, axis=0)\n",
    "            std_values = np.std(entropy_values, axis=0)\n",
    "            \n",
    "            ax.errorbar(reduction_levels, mean_values, yerr=std_values,\n",
    "                       label=f'{family_name}',\n",
    "                       color=colors[family_name],\n",
    "                       marker=markers[family_name],\n",
    "                       markersize=8,\n",
    "                       linewidth=2,\n",
    "                       capsize=5)\n",
    "    \n",
    "    ax.set_xlabel('Graph Portion (%)', fontsize=12)\n",
    "    ax.set_ylabel('Normalized Entropy', fontsize=12)\n",
    "    ax.set_title(f'Entropy Reduction Patterns for {node_size}-node Networks', \n",
    "                 fontsize=14)\n",
    "    ax.grid(True, linestyle='--', alpha=0.3)\n",
    "    ax.set_xticks(reduction_levels)\n",
    "    ax.invert_xaxis()\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_family_sizes(json_data, family_name, figsize=(15, 10)):\n",
    "    \"\"\"Plot all sizes for a specific family.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    reduction_levels = [100, 80, 60, 40, 20]\n",
    "    \n",
    "    colors = {500: 'blue', 1500: 'red', 2500: 'green'}\n",
    "    markers = {500: 'o', 1500: 's', 2500: '^'}\n",
    "    \n",
    "    for size in [500, 1500, 2500]:\n",
    "        entropy_values = []\n",
    "        \n",
    "        # Get all graphs of this size\n",
    "        for graph_name, graph_data in json_data[family_name].items():\n",
    "            if f\"{size}\" in graph_name:\n",
    "                values = [graph_data['reductions'][str(level)]['entropy_arithmetic']['normalized'] \n",
    "                         for level in reduction_levels]\n",
    "                entropy_values.append(values)\n",
    "        \n",
    "        # Plot average with error bars\n",
    "        if entropy_values:\n",
    "            mean_values = np.mean(entropy_values, axis=0)\n",
    "            std_values = np.std(entropy_values, axis=0)\n",
    "            \n",
    "            ax.errorbar(reduction_levels, mean_values, yerr=std_values,\n",
    "                       label=f'{size} nodes',\n",
    "                       color=colors[size],\n",
    "                       marker=markers[size],\n",
    "                       markersize=8,\n",
    "                       linewidth=2,\n",
    "                       capsize=5)\n",
    "    \n",
    "    ax.set_xlabel('Graph Portion (%)', fontsize=12)\n",
    "    ax.set_ylabel('Normalized Entropy', fontsize=12)\n",
    "    ax.set_title(f'Entropy Reduction Patterns for {family_name} Networks', \n",
    "                 fontsize=14)\n",
    "    ax.grid(True, linestyle='--', alpha=0.3)\n",
    "    ax.set_xticks(reduction_levels)\n",
    "    ax.invert_xaxis()\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Load data and create plots\n",
    "with open('synthetic_graphs_analysis.json', 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "# Plot by size\n",
    "for size in [2500, 1500, 500]:\n",
    "    fig = plot_size_specific(json_data, size)\n",
    "    plt.savefig(f'entropy_size_{size}.png', bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# Plot by family\n",
    "for family in ['ring', 'barabasi', 'regular', 'grid']:\n",
    "    fig = plot_family_sizes(json_data, family)\n",
    "    plt.savefig(f'entropy_family_{family}.png', bbox_inches='tight', dpi=300)\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
